apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: simple-pytorch-training-pipeline-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.22, pipelines.kubeflow.org/pipeline_compilation_time: '2024-01-15T16:34:40.419230',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "An example pipeline that
      trains a simple PyTorch model.", "inputs": [{"name": "model_name", "type": "String"}],
      "name": "Simple PyTorch Training Pipeline"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.22}
spec:
  entrypoint: simple-pytorch-training-pipeline
  templates:
  - name: load-data
    container:
      args: [--x, /tmp/outputs/x/data, --y, /tmp/outputs/y/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'torch' 'dill' 'numpy' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install
        --quiet --no-warn-script-location 'torch' 'dill' 'numpy' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def load_data(
            x_path,
            y_path,
        ):
            import torch
            import dill

            x = torch.randn(100, 10)
            y = torch.randn(100, 1)

            with open(x_path, "wb") as f:
                dill.dump(x, f)
            with open(y_path, "wb") as f:
                dill.dump(y, f)

        import argparse
        _parser = argparse.ArgumentParser(prog='Load data', description='')
        _parser.add_argument("--x", dest="x_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--y", dest="y_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = load_data(**_parsed_args)
      image: python:3.7
    outputs:
      artifacts:
      - {name: load-data-x, path: /tmp/outputs/x/data}
      - {name: load-data-y, path: /tmp/outputs/y/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.22
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--x", {"outputPath": "x"}, "--y", {"outputPath": "y"}], "command":
          ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet
          --no-warn-script-location ''torch'' ''dill'' ''numpy'' || PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''torch'' ''dill''
          ''numpy'' --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path),
          exist_ok=True)\n    return file_path\n\ndef load_data(\n    x_path,\n    y_path,\n):\n    import
          torch\n    import dill\n\n    x = torch.randn(100, 10)\n    y = torch.randn(100,
          1)\n\n    with open(x_path, \"wb\") as f:\n        dill.dump(x, f)\n    with
          open(y_path, \"wb\") as f:\n        dill.dump(y, f)\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Load data'', description='''')\n_parser.add_argument(\"--x\",
          dest=\"x_path\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parser.add_argument(\"--y\", dest=\"y_path\",
          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = load_data(**_parsed_args)\n"],
          "image": "python:3.7"}}, "name": "Load data", "outputs": [{"name": "x",
          "type": "dill"}, {"name": "y", "type": "dill"}]}', pipelines.kubeflow.org/component_ref: '{}'}
  - name: simple-pytorch-training-pipeline
    inputs:
      parameters:
      - {name: model_name}
    dag:
      tasks:
      - {name: load-data, template: load-data}
      - name: train-model
        template: train-model
        dependencies: [load-data]
        arguments:
          artifacts:
          - {name: load-data-x, from: '{{tasks.load-data.outputs.artifacts.load-data-x}}'}
          - {name: load-data-y, from: '{{tasks.load-data.outputs.artifacts.load-data-y}}'}
      - name: upload-torch-model-to-mlflow
        template: upload-torch-model-to-mlflow
        dependencies: [train-model]
        arguments:
          parameters:
          - {name: model_name, value: '{{inputs.parameters.model_name}}'}
          artifacts:
          - {name: train-model-conda_env, from: '{{tasks.train-model.outputs.artifacts.train-model-conda_env}}'}
          - {name: train-model-input_example, from: '{{tasks.train-model.outputs.artifacts.train-model-input_example}}'}
          - {name: train-model-model, from: '{{tasks.train-model.outputs.artifacts.train-model-model}}'}
          - {name: train-model-signature, from: '{{tasks.train-model.outputs.artifacts.train-model-signature}}'}
  - name: train-model
    container:
      args: [--x, /tmp/inputs/x/data, --y, /tmp/inputs/y/data, --model, /tmp/outputs/model/data,
        --input-example, /tmp/outputs/input_example/data, --signature, /tmp/outputs/signature/data,
        --conda-env, /tmp/outputs/conda_env/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'torch' 'torchvision' 'dill' 'numpy' 'mlflow' || PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location 'torch' 'torchvision'
        'dill' 'numpy' 'mlflow' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def train_model(
            x_path,
            y_path,
            model_path,
            input_example_path,
            signature_path,
            conda_env_path,
        ):
            import torch
            import torch.nn as nn
            import torch.optim as optim
            import dill
            from mlflow.models.signature import infer_signature
            from mlflow.utils.environment import _mlflow_conda_env

            with open(x_path, "rb") as f:
                x = dill.load(f)
            with open(y_path, "rb") as f:
                y = dill.load(f)

            class SimpleNet(nn.Module):
                def __init__(self):
                    super(SimpleNet, self).__init__()
                    self.fc = nn.Linear(10, 1)

                def forward(self, x):
                    return self.fc(x)

            model = SimpleNet()
            criterion = nn.MSELoss()
            optimizer = optim.SGD(model.parameters(), lr=0.001)

            for epoch in range(2):
                optimizer.zero_grad()
                outputs = model(x)
                loss = criterion(outputs, y)
                loss.backward()
                optimizer.step()
                print(f"Epoch {epoch+1}, Loss: {loss.item()}")

            with open(model_path, "wb") as f:
                dill.dump(model, f)

            input_example = x[0:1].cpu().numpy()  # Convert to numpy array
            with open(input_example_path, "wb") as f:
                dill.dump(input_example, f)

            x_numpy = x.cpu().numpy()  # Convert input x to numpy array
            model.eval()  # Set model to evaluation mode
            output_numpy = (
                model(torch.from_numpy(x_numpy)).detach().cpu().numpy()
            )  # Get model output as numpy array
            signature = infer_signature(
                x_numpy, output_numpy
            )  # Use numpy arrays for infer_signature
            with open(signature_path, "wb") as f:
                dill.dump(signature, f)

            conda_env = _mlflow_conda_env(
                additional_pip_deps=["dill", "pandas", "torch", "mlflow"]
            )
            with open(conda_env_path, "wb") as file_writer:
                dill.dump(conda_env, file_writer)

        import argparse
        _parser = argparse.ArgumentParser(prog='Train model', description='')
        _parser.add_argument("--x", dest="x_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--y", dest="y_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--model", dest="model_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--input-example", dest="input_example_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--signature", dest="signature_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--conda-env", dest="conda_env_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = train_model(**_parsed_args)
      image: python:3.7
    inputs:
      artifacts:
      - {name: load-data-x, path: /tmp/inputs/x/data}
      - {name: load-data-y, path: /tmp/inputs/y/data}
    outputs:
      artifacts:
      - {name: train-model-conda_env, path: /tmp/outputs/conda_env/data}
      - {name: train-model-input_example, path: /tmp/outputs/input_example/data}
      - {name: train-model-model, path: /tmp/outputs/model/data}
      - {name: train-model-signature, path: /tmp/outputs/signature/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.22
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--x", {"inputPath": "x"}, "--y", {"inputPath": "y"}, "--model",
          {"outputPath": "model"}, "--input-example", {"outputPath": "input_example"},
          "--signature", {"outputPath": "signature"}, "--conda-env", {"outputPath":
          "conda_env"}], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''torch'' ''torchvision''
          ''dill'' ''numpy'' ''mlflow'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
          -m pip install --quiet --no-warn-script-location ''torch'' ''torchvision''
          ''dill'' ''numpy'' ''mlflow'' --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path),
          exist_ok=True)\n    return file_path\n\ndef train_model(\n    x_path,\n    y_path,\n    model_path,\n    input_example_path,\n    signature_path,\n    conda_env_path,\n):\n    import
          torch\n    import torch.nn as nn\n    import torch.optim as optim\n    import
          dill\n    from mlflow.models.signature import infer_signature\n    from
          mlflow.utils.environment import _mlflow_conda_env\n\n    with open(x_path,
          \"rb\") as f:\n        x = dill.load(f)\n    with open(y_path, \"rb\") as
          f:\n        y = dill.load(f)\n\n    class SimpleNet(nn.Module):\n        def
          __init__(self):\n            super(SimpleNet, self).__init__()\n            self.fc
          = nn.Linear(10, 1)\n\n        def forward(self, x):\n            return
          self.fc(x)\n\n    model = SimpleNet()\n    criterion = nn.MSELoss()\n    optimizer
          = optim.SGD(model.parameters(), lr=0.001)\n\n    for epoch in range(2):\n        optimizer.zero_grad()\n        outputs
          = model(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        print(f\"Epoch
          {epoch+1}, Loss: {loss.item()}\")\n\n    with open(model_path, \"wb\") as
          f:\n        dill.dump(model, f)\n\n    input_example = x[0:1].cpu().numpy()  #
          Convert to numpy array\n    with open(input_example_path, \"wb\") as f:\n        dill.dump(input_example,
          f)\n\n    x_numpy = x.cpu().numpy()  # Convert input x to numpy array\n    model.eval()  #
          Set model to evaluation mode\n    output_numpy = (\n        model(torch.from_numpy(x_numpy)).detach().cpu().numpy()\n    )  #
          Get model output as numpy array\n    signature = infer_signature(\n        x_numpy,
          output_numpy\n    )  # Use numpy arrays for infer_signature\n    with open(signature_path,
          \"wb\") as f:\n        dill.dump(signature, f)\n\n    conda_env = _mlflow_conda_env(\n        additional_pip_deps=[\"dill\",
          \"pandas\", \"torch\", \"mlflow\"]\n    )\n    with open(conda_env_path,
          \"wb\") as file_writer:\n        dill.dump(conda_env, file_writer)\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Train model'', description='''')\n_parser.add_argument(\"--x\",
          dest=\"x_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--y\",
          dest=\"y_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model\",
          dest=\"model_path\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parser.add_argument(\"--input-example\", dest=\"input_example_path\",
          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--signature\",
          dest=\"signature_path\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parser.add_argument(\"--conda-env\", dest=\"conda_env_path\",
          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = train_model(**_parsed_args)\n"],
          "image": "python:3.7"}}, "inputs": [{"name": "x", "type": "dill"}, {"name":
          "y", "type": "dill"}], "name": "Train model", "outputs": [{"name": "model",
          "type": "dill"}, {"name": "input_example", "type": "dill"}, {"name": "signature",
          "type": "dill"}, {"name": "conda_env", "type": "dill"}]}', pipelines.kubeflow.org/component_ref: '{}'}
  - name: upload-torch-model-to-mlflow
    container:
      args: [--model-name, '{{inputs.parameters.model_name}}', --model, /tmp/inputs/model/data,
        --input-example, /tmp/inputs/input_example/data, --signature, /tmp/inputs/signature/data,
        --conda-env, /tmp/inputs/conda_env/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'dill' 'mlflow' 'torch' 'boto3' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
        -m pip install --quiet --no-warn-script-location 'dill' 'mlflow' 'torch' 'boto3'
        --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def upload_torch_model_to_mlflow(
            model_name,
            model_path,
            input_example_path,
            signature_path,
            conda_env_path,
        ):
            import os
            import dill
            from mlflow.pytorch import save_model
            from mlflow.tracking.client import MlflowClient

            os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://minio-service.kubeflow.svc:9000"
            os.environ["AWS_ACCESS_KEY_ID"] = "minio"
            os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"

            client = MlflowClient("http://mlflow-server-service.mlflow-system.svc:5000")

            with open(model_path, mode="rb") as f:
                model = dill.load(f)

            with open(input_example_path, "rb") as f:
                input_example = dill.load(f)

            with open(signature_path, "rb") as f:
                signature = dill.load(f)

            with open(conda_env_path, "rb") as f:
                conda_env = dill.load(f)

            save_model(
                pytorch_model=model,
                path=model_name,
                conda_env=conda_env,
                signature=signature,
                input_example=input_example,
            )
            run = client.create_run(experiment_id="0")
            client.log_artifact(run.info.run_id, model_name)

        import argparse
        _parser = argparse.ArgumentParser(prog='Upload torch model to mlflow', description='')
        _parser.add_argument("--model-name", dest="model_name", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--model", dest="model_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--input-example", dest="input_example_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--signature", dest="signature_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--conda-env", dest="conda_env_path", type=str, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = upload_torch_model_to_mlflow(**_parsed_args)
      image: python:3.7
    inputs:
      parameters:
      - {name: model_name}
      artifacts:
      - {name: train-model-conda_env, path: /tmp/inputs/conda_env/data}
      - {name: train-model-input_example, path: /tmp/inputs/input_example/data}
      - {name: train-model-model, path: /tmp/inputs/model/data}
      - {name: train-model-signature, path: /tmp/inputs/signature/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.22
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--model-name", {"inputValue": "model_name"}, "--model", {"inputPath":
          "model"}, "--input-example", {"inputPath": "input_example"}, "--signature",
          {"inputPath": "signature"}, "--conda-env", {"inputPath": "conda_env"}],
          "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
          install --quiet --no-warn-script-location ''dill'' ''mlflow'' ''torch''
          ''boto3'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet
          --no-warn-script-location ''dill'' ''mlflow'' ''torch'' ''boto3'' --user)
          && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
          > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def upload_torch_model_to_mlflow(\n    model_name,\n    model_path,\n    input_example_path,\n    signature_path,\n    conda_env_path,\n):\n    import
          os\n    import dill\n    from mlflow.pytorch import save_model\n    from
          mlflow.tracking.client import MlflowClient\n\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"]
          = \"http://minio-service.kubeflow.svc:9000\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"]
          = \"minio\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n\n    client
          = MlflowClient(\"http://mlflow-server-service.mlflow-system.svc:5000\")\n\n    with
          open(model_path, mode=\"rb\") as f:\n        model = dill.load(f)\n\n    with
          open(input_example_path, \"rb\") as f:\n        input_example = dill.load(f)\n\n    with
          open(signature_path, \"rb\") as f:\n        signature = dill.load(f)\n\n    with
          open(conda_env_path, \"rb\") as f:\n        conda_env = dill.load(f)\n\n    save_model(\n        pytorch_model=model,\n        path=model_name,\n        conda_env=conda_env,\n        signature=signature,\n        input_example=input_example,\n    )\n    run
          = client.create_run(experiment_id=\"0\")\n    client.log_artifact(run.info.run_id,
          model_name)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Upload
          torch model to mlflow'', description='''')\n_parser.add_argument(\"--model-name\",
          dest=\"model_name\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model\",
          dest=\"model_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--input-example\",
          dest=\"input_example_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--signature\",
          dest=\"signature_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--conda-env\",
          dest=\"conda_env_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = upload_torch_model_to_mlflow(**_parsed_args)\n"],
          "image": "python:3.7"}}, "inputs": [{"name": "model_name", "type": "String"},
          {"name": "model", "type": "dill"}, {"name": "input_example", "type": "dill"},
          {"name": "signature", "type": "dill"}, {"name": "conda_env", "type": "dill"}],
          "name": "Upload torch model to mlflow"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"model_name": "{{inputs.parameters.model_name}}"}'}
  arguments:
    parameters:
    - {name: model_name}
  serviceAccountName: pipeline-runner
