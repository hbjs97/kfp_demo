apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: pytorch-mnist-prediction-pipeline-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.22, pipelines.kubeflow.org/pipeline_compilation_time: '2024-01-15T23:01:21.231793',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "Pipeline for predicting
      MNIST dataset using a PyTorch model.", "inputs": [{"name": "model_name", "type":
      "String"}], "name": "PyTorch MNIST Prediction Pipeline"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.22}
spec:
  entrypoint: pytorch-mnist-prediction-pipeline
  templates:
  - name: mnist-model-train
    container:
      args: [--model, /tmp/outputs/model/data, --input-example, /tmp/outputs/input_example/data,
        --signature, /tmp/outputs/signature/data, --conda-env, /tmp/outputs/conda_env/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'torch' 'torchvision' 'numpy' 'dill' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
        -m pip install --quiet --no-warn-script-location 'torch' 'torchvision' 'numpy'
        'dill' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def mnist_model_train(
            model_path,
            input_example_path,
            signature_path,
            conda_env_path,
        ):
            import torch
            import torch.nn as nn
            import torch.nn.functional as F
            import dill
            from torchvision import transforms
            from mlflow.models.signature import infer_signature
            from mlflow.utils.environment import _mlflow_conda_env

            # Define the neural network model
            class Net(nn.Module):
                def __init__(self):
                    super(Net, self).__init__()
                    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
                    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
                    self.conv2_drop = nn.Dropout2d()
                    self.fc1 = nn.Linear(320, 50)
                    self.fc2 = nn.Linear(50, 10)

                def forward(self, x):
                    x = F.relu(F.max_pool2d(self.conv1(x), 2))
                    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
                    x = x.view(-1, 320)
                    x = F.relu(self.fc1(x))
                    x = F.dropout(x, training=self.training)
                    x = self.fc2(x)
                    return F.log_softmax(x)

            # Create and save the model
            model = Net()

            # Prepare an input example and infer the signature
            input_example = torch.randn(1, 1, 28, 28)  # Example input tensor
            model.eval()  # Set the model to evaluation mode
            with torch.no_grad():
                output_example = model(input_example)

            # Save the model
            with open(model_path, "wb") as f:
                dill.dump(model, f)

            # Save the input example
            with open(input_example_path, "wb") as f:
                dill.dump(input_example, f)

            # Infer and save the signature
            signature = infer_signature(input_example.numpy(), output_example.numpy())
            with open(signature_path, "wb") as f:
                dill.dump(signature, f)

            # Create and save the conda environment
            conda_env = _mlflow_conda_env(
                additional_pip_deps=["torch", "numpy", "dill", "mlflow"]
            )
            with open(conda_env_path, "wb") as f:
                dill.dump(conda_env, f)

        import argparse
        _parser = argparse.ArgumentParser(prog='Mnist model train', description='')
        _parser.add_argument("--model", dest="model_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--input-example", dest="input_example_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--signature", dest="signature_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--conda-env", dest="conda_env_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = mnist_model_train(**_parsed_args)
      image: python:3.7
    outputs:
      artifacts:
      - {name: mnist-model-train-conda_env, path: /tmp/outputs/conda_env/data}
      - {name: mnist-model-train-input_example, path: /tmp/outputs/input_example/data}
      - {name: mnist-model-train-model, path: /tmp/outputs/model/data}
      - {name: mnist-model-train-signature, path: /tmp/outputs/signature/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.22
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--model", {"outputPath": "model"}, "--input-example", {"outputPath":
          "input_example"}, "--signature", {"outputPath": "signature"}, "--conda-env",
          {"outputPath": "conda_env"}], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''torch'' ''torchvision''
          ''numpy'' ''dill'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install
          --quiet --no-warn-script-location ''torch'' ''torchvision'' ''numpy'' ''dill''
          --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path),
          exist_ok=True)\n    return file_path\n\ndef mnist_model_train(\n    model_path,\n    input_example_path,\n    signature_path,\n    conda_env_path,\n):\n    import
          torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n    import
          dill\n    from torchvision import transforms\n    from mlflow.models.signature
          import infer_signature\n    from mlflow.utils.environment import _mlflow_conda_env\n\n    #
          Define the neural network model\n    class Net(nn.Module):\n        def
          __init__(self):\n            super(Net, self).__init__()\n            self.conv1
          = nn.Conv2d(1, 10, kernel_size=5)\n            self.conv2 = nn.Conv2d(10,
          20, kernel_size=5)\n            self.conv2_drop = nn.Dropout2d()\n            self.fc1
          = nn.Linear(320, 50)\n            self.fc2 = nn.Linear(50, 10)\n\n        def
          forward(self, x):\n            x = F.relu(F.max_pool2d(self.conv1(x), 2))\n            x
          = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n            x
          = x.view(-1, 320)\n            x = F.relu(self.fc1(x))\n            x =
          F.dropout(x, training=self.training)\n            x = self.fc2(x)\n            return
          F.log_softmax(x)\n\n    # Create and save the model\n    model = Net()\n\n    #
          Prepare an input example and infer the signature\n    input_example = torch.randn(1,
          1, 28, 28)  # Example input tensor\n    model.eval()  # Set the model to
          evaluation mode\n    with torch.no_grad():\n        output_example = model(input_example)\n\n    #
          Save the model\n    with open(model_path, \"wb\") as f:\n        dill.dump(model,
          f)\n\n    # Save the input example\n    with open(input_example_path, \"wb\")
          as f:\n        dill.dump(input_example, f)\n\n    # Infer and save the signature\n    signature
          = infer_signature(input_example.numpy(), output_example.numpy())\n    with
          open(signature_path, \"wb\") as f:\n        dill.dump(signature, f)\n\n    #
          Create and save the conda environment\n    conda_env = _mlflow_conda_env(\n        additional_pip_deps=[\"torch\",
          \"numpy\", \"dill\", \"mlflow\"]\n    )\n    with open(conda_env_path, \"wb\")
          as f:\n        dill.dump(conda_env, f)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Mnist
          model train'', description='''')\n_parser.add_argument(\"--model\", dest=\"model_path\",
          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--input-example\",
          dest=\"input_example_path\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parser.add_argument(\"--signature\", dest=\"signature_path\",
          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--conda-env\",
          dest=\"conda_env_path\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = mnist_model_train(**_parsed_args)\n"], "image": "python:3.7"}}, "name":
          "Mnist model train", "outputs": [{"name": "model", "type": "dill"}, {"name":
          "input_example", "type": "dill"}, {"name": "signature", "type": "dill"},
          {"name": "conda_env", "type": "dill"}]}', pipelines.kubeflow.org/component_ref: '{}'}
  - name: pytorch-mnist-prediction-pipeline
    inputs:
      parameters:
      - {name: model_name}
    dag:
      tasks:
      - {name: mnist-model-train, template: mnist-model-train}
      - name: upload-mlflow-artifacts
        template: upload-mlflow-artifacts
        dependencies: [mnist-model-train]
        arguments:
          parameters:
          - {name: model_name, value: '{{inputs.parameters.model_name}}'}
          artifacts:
          - {name: mnist-model-train-conda_env, from: '{{tasks.mnist-model-train.outputs.artifacts.mnist-model-train-conda_env}}'}
          - {name: mnist-model-train-input_example, from: '{{tasks.mnist-model-train.outputs.artifacts.mnist-model-train-input_example}}'}
          - {name: mnist-model-train-model, from: '{{tasks.mnist-model-train.outputs.artifacts.mnist-model-train-model}}'}
          - {name: mnist-model-train-signature, from: '{{tasks.mnist-model-train.outputs.artifacts.mnist-model-train-signature}}'}
  - name: upload-mlflow-artifacts
    container:
      args: [--model-name, '{{inputs.parameters.model_name}}', --model, /tmp/inputs/model/data,
        --input-example, /tmp/inputs/input_example/data, --signature, /tmp/inputs/signature/data,
        --conda-env, /tmp/inputs/conda_env/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'torch' 'numpy' 'dill' 'mlflow' 'boto3' || PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location 'torch' 'numpy' 'dill'
        'mlflow' 'boto3' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def upload_mlflow_artifacts(
            model_name,
            model_path,
            input_example_path,
            signature_path,
            conda_env_path,
        ):
            import os
            import dill
            from mlflow.pytorch import save_model
            from mlflow.tracking.client import MlflowClient

            os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://minio-service.kubeflow.svc:9000"
            os.environ["AWS_ACCESS_KEY_ID"] = "minio"
            os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"

            client = MlflowClient("http://mlflow-server-service.mlflow-system.svc:5000")

            with open(model_path, mode="rb") as f:
                model = dill.load(f)

            with open(input_example_path, "rb") as f:
                input_example = dill.load(f)

            with open(signature_path, "rb") as f:
                signature = dill.load(f)

            with open(conda_env_path, "rb") as f:
                conda_env = dill.load(f)

            save_model(
                pytorch_model=model,
                path=model_name,
                conda_env=conda_env,
                signature=signature,
                input_example=input_example,
            )
            run = client.create_run(experiment_id="0")
            client.log_artifact(run.info.run_id, model_name)

        import argparse
        _parser = argparse.ArgumentParser(prog='Upload mlflow artifacts', description='')
        _parser.add_argument("--model-name", dest="model_name", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--model", dest="model_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--input-example", dest="input_example_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--signature", dest="signature_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--conda-env", dest="conda_env_path", type=str, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = upload_mlflow_artifacts(**_parsed_args)
      image: python:3.7
    inputs:
      parameters:
      - {name: model_name}
      artifacts:
      - {name: mnist-model-train-conda_env, path: /tmp/inputs/conda_env/data}
      - {name: mnist-model-train-input_example, path: /tmp/inputs/input_example/data}
      - {name: mnist-model-train-model, path: /tmp/inputs/model/data}
      - {name: mnist-model-train-signature, path: /tmp/inputs/signature/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.22
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--model-name", {"inputValue": "model_name"}, "--model", {"inputPath":
          "model"}, "--input-example", {"inputPath": "input_example"}, "--signature",
          {"inputPath": "signature"}, "--conda-env", {"inputPath": "conda_env"}],
          "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
          install --quiet --no-warn-script-location ''torch'' ''numpy'' ''dill'' ''mlflow''
          ''boto3'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet
          --no-warn-script-location ''torch'' ''numpy'' ''dill'' ''mlflow'' ''boto3''
          --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def upload_mlflow_artifacts(\n    model_name,\n    model_path,\n    input_example_path,\n    signature_path,\n    conda_env_path,\n):\n    import
          os\n    import dill\n    from mlflow.pytorch import save_model\n    from
          mlflow.tracking.client import MlflowClient\n\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"]
          = \"http://minio-service.kubeflow.svc:9000\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"]
          = \"minio\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n\n    client
          = MlflowClient(\"http://mlflow-server-service.mlflow-system.svc:5000\")\n\n    with
          open(model_path, mode=\"rb\") as f:\n        model = dill.load(f)\n\n    with
          open(input_example_path, \"rb\") as f:\n        input_example = dill.load(f)\n\n    with
          open(signature_path, \"rb\") as f:\n        signature = dill.load(f)\n\n    with
          open(conda_env_path, \"rb\") as f:\n        conda_env = dill.load(f)\n\n    save_model(\n        pytorch_model=model,\n        path=model_name,\n        conda_env=conda_env,\n        signature=signature,\n        input_example=input_example,\n    )\n    run
          = client.create_run(experiment_id=\"0\")\n    client.log_artifact(run.info.run_id,
          model_name)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Upload
          mlflow artifacts'', description='''')\n_parser.add_argument(\"--model-name\",
          dest=\"model_name\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model\",
          dest=\"model_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--input-example\",
          dest=\"input_example_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--signature\",
          dest=\"signature_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--conda-env\",
          dest=\"conda_env_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = upload_mlflow_artifacts(**_parsed_args)\n"],
          "image": "python:3.7"}}, "inputs": [{"name": "model_name", "type": "String"},
          {"name": "model", "type": "dill"}, {"name": "input_example", "type": "dill"},
          {"name": "signature", "type": "dill"}, {"name": "conda_env", "type": "dill"}],
          "name": "Upload mlflow artifacts"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"model_name": "{{inputs.parameters.model_name}}"}'}
  arguments:
    parameters:
    - {name: model_name}
  serviceAccountName: pipeline-runner
